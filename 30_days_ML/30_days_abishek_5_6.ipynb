{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5369483-16ba-443d-bce7-35bbbf3ecb9c",
   "metadata": {},
   "source": [
    "# Intro to 4BAI Kaggle 30 days of ML competition\n",
    "\n",
    "## contributors\n",
    "* Labbe, Chris (gclabbe)\n",
    "\n",
    "### Notes\n",
    "It appears from online discussions that this particular data works better with CPU.  So, GPU is good for rapid iteration through options, however, final computations for submission need to be run on CPU which can take 30+ minutes depending on the number of folds.\n",
    "\n",
    "### Revisions to 30_days_abishek_1.ipynb\n",
    "* V5 - \n",
    "* V6 - 10-fold with params from raw GridSearchCV\n",
    "* V7 - failed compile because of grid search layout\n",
    "* V8 - need to remember to disable GPU in XGB when saving with CPU\n",
    "* V9 - 10-fold with params from tutorial ... this version\n",
    "\n",
    "### Revisions to 30_days_abishek_5_6.ipynb (this notebook)\n",
    "* V10 \n",
    "\n",
    "### Plans\n",
    "* Tutorial 6 -- shows how to pull all of the different models together as a stack\n",
    "\n",
    "These tutorials are laying out the code long-hand ... no functions to clean up repetitive tasks. So, instead of forking and operating like others are doing, let's build out some support functions and clean up the code.\n",
    "\n",
    "Also, need to understand how the optimized parameters for a couple of the models were discovered.  Abishek mentions a kernel that he leveraged from ... https://www.kaggle.com/stevenrferrer/30-days-of-ml-optimized-xgboost-5folds\n",
    "\n",
    "Here is Abishek talking about tuning specifically for this challenge ... https://www.youtube.com/watch?v=m5YSKPMjkrk.  He has many videos online and mentions a longer parameter tuning video that is not challenge specific.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349f66a2-c348-4371-8a4a-c73660f827d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0172a8e35604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=go.Bar(y=[2, 3, 1]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c60a2-db7f-448a-98cc-e9c7456ae782",
   "metadata": {
    "tags": []
   },
   "source": [
    "Welcome to the **[30 Days of ML competition](https://www.kaggle.com/c/30-days-of-ml/overview)**!  In this notebook, you'll learn how to make your first submission.\n",
    "\n",
    "Before getting started, make your own editable copy of this notebook by clicking on the **Copy and Edit** button.\n",
    "\n",
    "# Step 1: Import helpful libraries\n",
    "\n",
    "We begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72600a5a-c2f5-4c2c-b898-14f77c8eaf79",
   "metadata": {},
   "source": [
    "### This version of the notebook will follow the tutorials published by Abishek\n",
    "https://www.kaggle.com/abhishek/\n",
    "\n",
    "* part-1: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa035e-98de-4558-8885-7b6146b948d8",
   "metadata": {
    "id": "JWibA4lcO-P-"
   },
   "source": [
    "### Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d590d4a1-ce12-4a73-9751-72acedfcc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# modules called out in part-1\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# other modules from previous work\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Regressors\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# suppress \"torch\" warning in TPOT and GridSearchCV warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d614e-a197-40e9-b229-6f30a1c56ca0",
   "metadata": {},
   "source": [
    "# Step 2: Load the data\n",
    "\n",
    "Next, we'll load the training and test data.  \n",
    "\n",
    "We set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68abc517-d3c9-464d-a232-d017268ae4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "path = \"\"  # \"../input/30-days-of-ml/\"\n",
    "\n",
    "df_train = pd.read_csv(f\"{path}train.csv\")\n",
    "df_test = pd.read_csv(f\"{path}test.csv\")\n",
    "sample_submission = pd.read_csv(f\"{path}sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b1c65-244b-4354-96b1-ded3f5101f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"../input/stacking30days/train_pred_1.csv\")\n",
    "df1.columns = [\"id\", \"pred_1\"]\n",
    "df2 = pd.read_csv(\"../input/stacking30days/train_pred_2.csv\")\n",
    "df2.columns = [\"id\", \"pred_2\"]\n",
    "df3 = pd.read_csv(\"../input/stacking30days/train_pred_3.csv\")\n",
    "df3.columns = [\"id\", \"pred_3\"]\n",
    "df4 = pd.read_csv(\"../input/stacking30days/train_pred_4.csv\")\n",
    "df4.columns = [\"id\", \"pred_4\"]\n",
    "df5 = pd.read_csv(\"../input/stacking30days/train_pred_5.csv\")\n",
    "df5.columns = [\"id\", \"pred_5\"]\n",
    "\n",
    "df_test1 = pd.read_csv(\"../input/stacking30days/test_pred_1.csv\")\n",
    "df_test1.columns = [\"id\", \"pred_1\"]\n",
    "df_test2 = pd.read_csv(\"../input/stacking30days/test_pred_2.csv\")\n",
    "df_test2.columns = [\"id\", \"pred_2\"]\n",
    "df_test3 = pd.read_csv(\"../input/stacking30days/test_pred_3.csv\")\n",
    "df_test3.columns = [\"id\", \"pred_3\"]\n",
    "df_test4 = pd.read_csv(\"../input/stacking30days/test_pred_4.csv\")\n",
    "df_test4.columns = [\"id\", \"pred_4\"]\n",
    "df_test5 = pd.read_csv(\"../input/stacking30days/test_pred_5.csv\")\n",
    "df_test5.columns = [\"id\", \"pred_5\"]\n",
    "\n",
    "df = df.merge(df1, on=\"id\", how=\"left\")\n",
    "df = df.merge(df2, on=\"id\", how=\"left\")\n",
    "df = df.merge(df3, on=\"id\", how=\"left\")\n",
    "df = df.merge(df4, on=\"id\", how=\"left\")\n",
    "df = df.merge(df5, on=\"id\", how=\"left\")\n",
    "\n",
    "df_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test5, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed375f2-e010-4409-8775-48740142b3f6",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the data\n",
    "\n",
    "Next, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  \n",
    "\n",
    "In the **[Categorical Variables lesson](https://www.kaggle.com/alexisbcook/categorical-variables)** in the Intermediate Machine Learning course, you learned several different ways to encode categorical variables in a dataset.  In this notebook, we'll use ordinal encoding and save our encoded features as new variables `X` and `X_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89221efc-e290-41e2-97b2-7f496ee0f60d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implement KFold techniques\n",
    "posted in the discussions by KGM - Abishek Thakur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7aadb21-c4c2-4891-9681-b63eb18dc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_refold = True\n",
    "folds = 10\n",
    "\n",
    "# create train_folds.csv if it does not exist\n",
    "if not Path(\"train_folds.csv\").is_file() or force_refold==True:\n",
    "    df_train = pd.read_csv(f\"{path}train.csv\")\n",
    "    df_train[\"kfold\"] = -1\n",
    "\n",
    "    kf = model_selection.KFold(\n",
    "        n_splits=folds,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train)):\n",
    "        df_train.loc[valid_indicies, \"kfold\"] = fold\n",
    "\n",
    "    df_train.to_csv(\"train_folds.csv\", index=False)\n",
    "\n",
    "df_train = pd.read_csv(f\"{path}train_folds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50936020-5a27-47c9-81fe-8a171a6c589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont6  \\\n",
      "0            1    B    B    B    C    B    B    A    E    C  ...  0.160266   \n",
      "1            2    B    B    A    A    B    D    A    F    A  ...  0.558922   \n",
      "2            3    A    A    A    C    B    D    A    D    A  ...  0.375348   \n",
      "3            4    B    B    A    C    B    D    A    E    C  ...  0.239061   \n",
      "4            6    A    A    A    C    B    D    A    E    A  ...  0.420667   \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
      "299995  499993    B    B    A    A    B    D    A    E    A  ...  0.450538   \n",
      "299996  499996    A    B    A    C    B    B    A    E    E  ...  0.508502   \n",
      "299997  499997    B    B    A    C    B    C    A    E    G  ...  0.372425   \n",
      "299998  499998    A    B    A    C    B    B    A    E    E  ...  0.424243   \n",
      "299999  499999    A    A    A    C    A    D    A    E    A  ...  0.328669   \n",
      "\n",
      "           cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
      "0       0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n",
      "1       0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n",
      "2       0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n",
      "3       0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n",
      "4       0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "299995  0.934360  1.005077  0.853726  0.422541  1.063463  0.697685  0.506404   \n",
      "299996  0.358247  0.257825  0.433525  0.301015  0.268447  0.577055  0.823611   \n",
      "299997  0.364936  0.383224  0.551825  0.661007  0.629606  0.714139  0.245732   \n",
      "299998  0.382028  0.468819  0.351036  0.288768  0.611169  0.380254  0.332030   \n",
      "299999  0.789165  0.960406  0.776019  0.734707  0.484392  0.639754  0.689317   \n",
      "\n",
      "          target  kfold  \n",
      "0       8.113634      0  \n",
      "1       8.481233      4  \n",
      "2       8.364351      8  \n",
      "3       8.049253      6  \n",
      "4       7.972260      2  \n",
      "...          ...    ...  \n",
      "299995  7.945605      9  \n",
      "299996  7.326118      7  \n",
      "299997  8.706755      3  \n",
      "299998  7.229569      6  \n",
      "299999  8.631146      2  \n",
      "\n",
      "[300000 rows x 27 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fa171d6-20a6-42f7-aec0-d78ba9bb8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = [c for c in df_train.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "\n",
    "df_test = df_test[useful_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab88a0-429d-4ba1-8294-9bb54f96f1e3",
   "metadata": {},
   "source": [
    "## Feature encoding tests - Tutorial 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64939e-493a-4792-87dc-7df92cee63ea",
   "metadata": {},
   "source": [
    "### Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37b2697c-c03c-4a67-8f2f-fe32cba73473",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 0.72562 std 0.00109\n",
    "for col in numerical_cols:\n",
    "    df_train[col] = np.log1p(df_train[col])\n",
    "    df_test[col] = np.log1p(df_test[col])\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c82ef7-25d2-4197-9c52-4a88773a2a14",
   "metadata": {},
   "source": [
    "### Polynomial transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52af7a68-f6a2-470a-84e0-fcb3519e6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 0.72963 std 0.00066\n",
    "poly = preprocessing.PolynomialFeatures(degree=3, interaction_only=True, include_bias=False)\n",
    "train_poly = poly.fit_transform(df[numerical_cols])\n",
    "test_poly = poly.fit_transform(df_test[numerical_cols])\n",
    "\n",
    "df_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\n",
    "df_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n",
    "\n",
    "df = pd.concat([df, df_poly], axis=1)\n",
    "df_test = pd.concat([df_test, df_test_poly], axis=1)\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "df_test = df_test[useful_features]\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27b7fb-c905-487d-b718-737bd973edeb",
   "metadata": {},
   "source": [
    "### Target Encoding (tutorial 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86ef2ec7-1818-491c-8791-bc14673234b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding\n",
    "for col in object_cols:\n",
    "    temp_df = []\n",
    "    temp_test_feat = None\n",
    "    for fold in range(folds):\n",
    "        x_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n",
    "        x_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        feat = x_train.groupby(col)[\"target\"].agg(\"mean\")\n",
    "        feat = feat.to_dict()\n",
    "\n",
    "        x_valid.loc[:, f\"tar_enc_{col}\"] = x_valid[col].map(feat)\n",
    "        temp_df.append(x_valid)\n",
    "\n",
    "        if temp_test_feat is None:\n",
    "            temp_test_feat = df_test[col].map(feat)\n",
    "        else:\n",
    "            temp_test_feat += df_test[col].map(feat)\n",
    "\n",
    "    temp_test_feat /= folds\n",
    "    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
    "    df_train = pd.concat(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe9513cb-b153-45f9-8674-10f9c315734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = [c for c in df_train.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "object_cols = [col for col in useful_features if col.startswith(\"cat\")]\n",
    "df_test = df_test[useful_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0b3e5-23c5-4796-bdac-257b0b69913b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 4: Train a model\n",
    "\n",
    "Now that the data is prepared, the next step is to train a model.  \n",
    "\n",
    "If you took the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** courses, then you learned about **[Random Forests](https://www.kaggle.com/dansbecker/random-forests)**.  In the code cell below, we fit a random forest model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a79ba9af-45d8-469e-81ab-7568955f6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.50936\n",
      "[1000]\tvalidation_0-rmse:0.72271\n",
      "[2000]\tvalidation_0-rmse:0.71880\n",
      "[3000]\tvalidation_0-rmse:0.71722\n",
      "[4000]\tvalidation_0-rmse:0.71647\n",
      "[5000]\tvalidation_0-rmse:0.71610\n",
      "[6000]\tvalidation_0-rmse:0.71593\n",
      "[6766]\tvalidation_0-rmse:0.71582\n",
      "time:  4.956782607237498\n",
      "0 0.715807786165432\n",
      "[0]\tvalidation_0-rmse:7.49115\n",
      "[1000]\tvalidation_0-rmse:0.72238\n",
      "[2000]\tvalidation_0-rmse:0.71843\n",
      "[3000]\tvalidation_0-rmse:0.71677\n",
      "[4000]\tvalidation_0-rmse:0.71591\n",
      "[5000]\tvalidation_0-rmse:0.71553\n",
      "[6000]\tvalidation_0-rmse:0.71533\n",
      "[7000]\tvalidation_0-rmse:0.71527\n",
      "[7139]\tvalidation_0-rmse:0.71529\n",
      "time:  5.279765991369883\n",
      "1 0.7152381792086441\n",
      "[0]\tvalidation_0-rmse:7.49700\n",
      "[1000]\tvalidation_0-rmse:0.72063\n",
      "[2000]\tvalidation_0-rmse:0.71684\n",
      "[3000]\tvalidation_0-rmse:0.71551\n",
      "[4000]\tvalidation_0-rmse:0.71487\n",
      "[5000]\tvalidation_0-rmse:0.71465\n",
      "[6000]\tvalidation_0-rmse:0.71454\n",
      "[7000]\tvalidation_0-rmse:0.71450\n",
      "[7756]\tvalidation_0-rmse:0.71455\n",
      "time:  5.923243029912313\n",
      "2 0.71447077947362\n",
      "[0]\tvalidation_0-rmse:7.49701\n",
      "[1000]\tvalidation_0-rmse:0.72395\n",
      "[2000]\tvalidation_0-rmse:0.71992\n",
      "[3000]\tvalidation_0-rmse:0.71823\n",
      "[4000]\tvalidation_0-rmse:0.71738\n",
      "[5000]\tvalidation_0-rmse:0.71694\n",
      "[6000]\tvalidation_0-rmse:0.71673\n",
      "[7000]\tvalidation_0-rmse:0.71666\n",
      "[7088]\tvalidation_0-rmse:0.71664\n",
      "time:  5.432153141498565\n",
      "3 0.7166263279417244\n",
      "[0]\tvalidation_0-rmse:7.49127\n",
      "[1000]\tvalidation_0-rmse:0.72823\n",
      "[2000]\tvalidation_0-rmse:0.72413\n",
      "[3000]\tvalidation_0-rmse:0.72242\n",
      "[4000]\tvalidation_0-rmse:0.72171\n",
      "[5000]\tvalidation_0-rmse:0.72129\n",
      "[6000]\tvalidation_0-rmse:0.72113\n",
      "[7000]\tvalidation_0-rmse:0.72104\n",
      "[7746]\tvalidation_0-rmse:0.72103\n",
      "time:  5.985011891523997\n",
      "4 0.7209966045495935\n",
      "[0]\tvalidation_0-rmse:7.49830\n",
      "[1000]\tvalidation_0-rmse:0.71980\n",
      "[2000]\tvalidation_0-rmse:0.71618\n",
      "[3000]\tvalidation_0-rmse:0.71477\n",
      "[4000]\tvalidation_0-rmse:0.71406\n",
      "[5000]\tvalidation_0-rmse:0.71382\n",
      "[6000]\tvalidation_0-rmse:0.71370\n",
      "[7000]\tvalidation_0-rmse:0.71370\n",
      "[7028]\tvalidation_0-rmse:0.71369\n",
      "time:  5.374301664034525\n",
      "5 0.713659366800696\n",
      "[0]\tvalidation_0-rmse:7.49920\n",
      "[1000]\tvalidation_0-rmse:0.72359\n",
      "[2000]\tvalidation_0-rmse:0.71971\n",
      "[3000]\tvalidation_0-rmse:0.71808\n",
      "[4000]\tvalidation_0-rmse:0.71727\n",
      "[5000]\tvalidation_0-rmse:0.71685\n",
      "[6000]\tvalidation_0-rmse:0.71661\n",
      "[6793]\tvalidation_0-rmse:0.71649\n",
      "time:  5.212849036852519\n",
      "6 0.7164752370983082\n",
      "[0]\tvalidation_0-rmse:7.49486\n",
      "[1000]\tvalidation_0-rmse:0.72417\n",
      "[2000]\tvalidation_0-rmse:0.72042\n",
      "[3000]\tvalidation_0-rmse:0.71889\n",
      "[4000]\tvalidation_0-rmse:0.71824\n",
      "[5000]\tvalidation_0-rmse:0.71791\n",
      "[6000]\tvalidation_0-rmse:0.71773\n",
      "[6747]\tvalidation_0-rmse:0.71772\n",
      "time:  5.206015650431315\n",
      "7 0.7176908114004193\n",
      "[0]\tvalidation_0-rmse:7.50006\n",
      "[1000]\tvalidation_0-rmse:0.72624\n",
      "[2000]\tvalidation_0-rmse:0.72206\n",
      "[3000]\tvalidation_0-rmse:0.72046\n",
      "[4000]\tvalidation_0-rmse:0.71968\n",
      "[5000]\tvalidation_0-rmse:0.71928\n",
      "[5828]\tvalidation_0-rmse:0.71920\n",
      "time:  4.435653412342072\n",
      "8 0.7191773890410059\n",
      "[0]\tvalidation_0-rmse:7.50482\n",
      "[1000]\tvalidation_0-rmse:0.72001\n",
      "[2000]\tvalidation_0-rmse:0.71554\n",
      "[3000]\tvalidation_0-rmse:0.71380\n",
      "[4000]\tvalidation_0-rmse:0.71295\n",
      "[5000]\tvalidation_0-rmse:0.71248\n",
      "[6000]\tvalidation_0-rmse:0.71217\n",
      "[7000]\tvalidation_0-rmse:0.71210\n",
      "[8000]\tvalidation_0-rmse:0.71200\n",
      "[8574]\tvalidation_0-rmse:0.71200\n",
      "time:  6.542887429396312\n",
      "9 0.7119740126343623\n",
      "\n",
      "Average MAE: 0.716212\tStd: 0.0025\n"
     ]
    }
   ],
   "source": [
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    x_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n",
    "    x_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n",
    "    x_test = df_test.copy()\n",
    "\n",
    "    valid_ids = x_valid.id.values.tolist()\n",
    "\n",
    "    y_train = x_train.target\n",
    "    y_valid = x_valid.target\n",
    "\n",
    "    x_train = x_train[useful_features]\n",
    "    x_valid = x_valid[useful_features]\n",
    "\n",
    "    # encode categorical columns\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    x_train[object_cols] = ordinal_encoder.fit_transform(x_train[object_cols])\n",
    "    x_valid[object_cols] = ordinal_encoder.transform(x_valid[object_cols])\n",
    "    x_test[object_cols] = ordinal_encoder.transform(x_test[object_cols])\n",
    "\n",
    "    # standardize numerical columns\n",
    "    \n",
    "    # 0.725506 std 0.00119\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    x_train[numerical_cols] = scaler.fit_transform(x_train[numerical_cols])\n",
    "    x_valid[numerical_cols] = scaler.transform(x_valid[numerical_cols])\n",
    "    x_test[numerical_cols] = scaler.transform(x_test[numerical_cols])\n",
    "    \n",
    "\n",
    "    # binning of numerical features\n",
    "    '''\n",
    "    # 0.72550 std 0.00088\n",
    "    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n",
    "    xvalid_ohe = ohe.transform(xvalid[object_cols])\n",
    "    xtest_ohe = ohe.transform(xtest[object_cols])\n",
    "\n",
    "    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n",
    "    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n",
    "    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n",
    "    '''\n",
    "\n",
    "    xgb_params_tutorial = {\n",
    "        'random_state': fold,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "\n",
    "    xgb_params_from_gridsearch = {\n",
    "        # 'tree_method': 'hist',  # 'hist',\n",
    "        'booster': 'gbtree',\n",
    "        'predictor': 'cpu_predictor',\n",
    "        'n_estimators': 10000,\n",
    "        'learning_rate': 0.03628302216953097,\n",
    "        'reg_lambda': 0.0008746338866473539,\n",
    "        'reg_alpha': 23.13181079976304,\n",
    "        'subsample': 0.7875490025178415,\n",
    "        'colsample_bytree': 0.11807135201147481,\n",
    "        'max_depth': 3,\n",
    "        'random_state': 0,\n",
    "        # 'n_jobs': -1,\n",
    "        # 'gpu_id': 0,\n",
    "        # 'single_precision_histogram': True,\n",
    "    }\n",
    "\n",
    "    # xgb_model = XGBRegressor(**xgb_params_tutorial)\n",
    "    xgb_model = XGBRegressor(**xgb_params_from_gridsearch)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    xgb_model.fit(\n",
    "        x_train, y_train,\n",
    "        early_stopping_rounds=300,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        verbose=1000\n",
    "    )\n",
    "\n",
    "    print('time: ', (time.time() - start) / 60.0)\n",
    "\n",
    "    preds_valid = xgb_model.predict(x_valid)\n",
    "    test_preds = xgb_model.predict(x_test)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    \n",
    "    mae = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    scores.append(mae)\n",
    "\n",
    "    print(fold, mae)\n",
    "\n",
    "print(f\"\\nAverage MAE: {np.mean(scores) :0.6f}\\tStd: {np.std(scores) :0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d66c4-0151-4aff-a415-4d562c1d89e9",
   "metadata": {},
   "source": [
    "### Current best score\n",
    "    Local:         0.71659 (V10 CPU 5-fold optimized params)\n",
    "    Kaggle-test:   0.????? (V9 CPU 10-fold)\n",
    "    Kaggle-result: 0.71751 (V9 CPU 10-fold)\n",
    "\n",
    "K-Fold tutorial run as published results in:\n",
    "\n",
    "    avg ~= 0.725\n",
    "    \n",
    "With XGB params from Sferrer & lesson 5:\n",
    "\n",
    "    Local:        0.71659 (V10 CPU 5-fold)\n",
    "    Kaggle-test:  0.71774 (GPU V10 10-fold)\n",
    "    Kagle-result: 0.71751 (CPU V9 10-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f013181b-4e70-4cfc-bd48-6ca1371b8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(np.column_stack(final_test_predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "122bea10-60b6-4bd5-b8f4-71e4bc075a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission.target = preds\n",
    "# sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b982e-cf83-4be6-8daf-b9ad5a144062",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 5: Submit to the competition\n",
    "\n",
    "We'll begin by using the trained model to generate predictions, which we'll save to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e49cd437-e84d-4de1-b71c-e853c970802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to generate predictions\n",
    "predictions = xgb_model.predict(x_test)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': x_test.index,\n",
    "                       'target': predictions})\n",
    "\n",
    "output.to_csv('tenc_5f.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741abbc-7adc-4b8e-b11f-f89dc28da4b7",
   "metadata": {},
   "source": [
    "## Stacking the different solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca209a-a7c5-4f49-b8d3-c144c1b7c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "\n",
    "    params = {\n",
    "        'random_state': 1, \n",
    "        'booster': 'gbtree',\n",
    "        'n_estimators': 7000,\n",
    "        'learning_rate': 0.03,\n",
    "        'max_depth': 2\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(\n",
    "        n_jobs=4,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_1\"]\n",
    "final_valid_predictions.to_csv(\"level1_train_pred_1.csv\", index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"id\", \"pred_1\"]\n",
    "sample_submission.to_csv(\"level1_test_pred_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2cc7da-6de0-4565-a682-aafa84feb174",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=500, n_jobs=-1, max_depth=3)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_2\"]\n",
    "final_valid_predictions.to_csv(\"level1_train_pred_2.csv\", index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"id\", \"pred_2\"]\n",
    "sample_submission.to_csv(\"level1_test_pred_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08722837-20ee-448a-9090-867dda140c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    model = GradientBoostingRegressor(n_estimators=500, max_depth=3)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_3\"]\n",
    "final_valid_predictions.to_csv(\"level1_train_pred_3.csv\", index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"id\", \"pred_3\"]\n",
    "sample_submission.to_csv(\"level1_test_pred_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d9325-a907-4c49-b133-f2a48a36ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"level1_train_pred_1.csv\")\n",
    "df2 = pd.read_csv(\"level1_train_pred_2.csv\")\n",
    "df3 = pd.read_csv(\"level1_train_pred_3.csv\")\n",
    "\n",
    "df_test1 = pd.read_csv(\"level1_test_pred_1.csv\")\n",
    "df_test2 = pd.read_csv(\"level1_test_pred_2.csv\")\n",
    "df_test3 = pd.read_csv(\"level1_test_pred_3.csv\")\n",
    "\n",
    "df = df.merge(df1, on=\"id\", how=\"left\")\n",
    "df = df.merge(df2, on=\"id\", how=\"left\")\n",
    "df = df.merge(df3, on=\"id\", how=\"left\")\n",
    "\n",
    "df_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec424e-57a3-439f-ae01-b1a886342469",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
