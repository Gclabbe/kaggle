{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d142247a-42ab-4d60-a808-5f996f57ad67",
   "metadata": {
    "tags": []
   },
   "source": [
    "Welcome to the **[30 Days of ML competition](https://www.kaggle.com/c/30-days-of-ml/overview)**!  In this notebook, you'll learn how to make your first submission.\n",
    "\n",
    "Before getting started, make your own editable copy of this notebook by clicking on the **Copy and Edit** button.\n",
    "\n",
    "# Step 1: Import helpful libraries\n",
    "\n",
    "We begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72600a5a-c2f5-4c2c-b898-14f77c8eaf79",
   "metadata": {},
   "source": [
    "### This version of the notebook will follow the tutorials published by Abishek\n",
    "https://www.kaggle.com/abhishek/\n",
    "\n",
    "* part-1: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353dc2e-f071-430b-a714-9eddcfae6eb1",
   "metadata": {},
   "source": [
    "### Tensorflow\n",
    "Including GPU support - sometimes - having trouble keeping tf-gpu working in Anaconda on Windoze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aed10f6-6d10-4e86-8111-9ff270d695d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(\n",
    "    gpu_options=tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8),\n",
    "    device_count={'GPU': 1},\n",
    "    # session = tf.compat.v1.Session(config=config) \n",
    "    # tf.compat.v1.keras.backend.set_session(session)\n",
    ")\n",
    "\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa035e-98de-4558-8885-7b6146b948d8",
   "metadata": {
    "id": "JWibA4lcO-P-"
   },
   "source": [
    "### Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d590d4a1-ce12-4a73-9751-72acedfcc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# modules called out in part-1\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# other modules from previous work\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Regressors\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# suppress \"torch\" warning in TPOT\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d614e-a197-40e9-b229-6f30a1c56ca0",
   "metadata": {},
   "source": [
    "# Step 2: Load the data\n",
    "\n",
    "Next, we'll load the training and test data.  \n",
    "\n",
    "We set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68abc517-d3c9-464d-a232-d017268ae4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "path = \"\"  # \"../input/30-days-of-ml/\"\n",
    "\n",
    "df_test = pd.read_csv(f\"{path}test.csv\")\n",
    "sample_submission = pd.read_csv(f\"{path}sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89221efc-e290-41e2-97b2-7f496ee0f60d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implement KFold techniques\n",
    "posted in the discussions by KGM - Abishek Thakur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7aadb21-c4c2-4891-9681-b63eb18dc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_folds.csv if it does not exist\n",
    "if not Path(\"train_folds.csv\").is_file():\n",
    "    df_train = pd.read_csv(f\"{path}train.csv\")\n",
    "    df_train[\"kfold\"] = -1\n",
    "\n",
    "    kf = model_selection.KFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train)):\n",
    "        df_train.loc[valid_indicies, \"kfold\"] = fold\n",
    "\n",
    "    df_train.to_csv(\"train_folds.csv\", index=False)\n",
    "\n",
    "df_train = pd.read_csv(f\"{path}train_folds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50936020-5a27-47c9-81fe-8a171a6c589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont6  \\\n",
      "0            1    B    B    B    C    B    B    A    E    C  ...  0.160266   \n",
      "1            2    B    B    A    A    B    D    A    F    A  ...  0.558922   \n",
      "2            3    A    A    A    C    B    D    A    D    A  ...  0.375348   \n",
      "3            4    B    B    A    C    B    D    A    E    C  ...  0.239061   \n",
      "4            6    A    A    A    C    B    D    A    E    A  ...  0.420667   \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
      "299995  499993    B    B    A    A    B    D    A    E    A  ...  0.450538   \n",
      "299996  499996    A    B    A    C    B    B    A    E    E  ...  0.508502   \n",
      "299997  499997    B    B    A    C    B    C    A    E    G  ...  0.372425   \n",
      "299998  499998    A    B    A    C    B    B    A    E    E  ...  0.424243   \n",
      "299999  499999    A    A    A    C    A    D    A    E    A  ...  0.328669   \n",
      "\n",
      "           cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
      "0       0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n",
      "1       0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n",
      "2       0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n",
      "3       0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n",
      "4       0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "299995  0.934360  1.005077  0.853726  0.422541  1.063463  0.697685  0.506404   \n",
      "299996  0.358247  0.257825  0.433525  0.301015  0.268447  0.577055  0.823611   \n",
      "299997  0.364936  0.383224  0.551825  0.661007  0.629606  0.714139  0.245732   \n",
      "299998  0.382028  0.468819  0.351036  0.288768  0.611169  0.380254  0.332030   \n",
      "299999  0.789165  0.960406  0.776019  0.734707  0.484392  0.639754  0.689317   \n",
      "\n",
      "          target  kfold  \n",
      "0       8.113634      0  \n",
      "1       8.481233      2  \n",
      "2       8.364351      4  \n",
      "3       8.049253      3  \n",
      "4       7.972260      1  \n",
      "...          ...    ...  \n",
      "299995  7.945605      4  \n",
      "299996  7.326118      3  \n",
      "299997  8.706755      1  \n",
      "299998  7.229569      3  \n",
      "299999  8.631146      1  \n",
      "\n",
      "[300000 rows x 27 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04408cc6-8806-4874-8927-0be15937b49c",
   "metadata": {},
   "source": [
    "??? Why are we stripping test to only the catX columns ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d50b2f1-0e16-4ce2-80e8-dd7afd7e3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = [c for c in df_train.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "\n",
    "df_test = df_test[useful_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f18088a-bb2b-4060-89ed-87efec8afe75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.389470</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.869850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668980</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.540150</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686964</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.648182</td>\n",
       "      <td>0.684501</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>1.000773</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.625849</td>\n",
       "      <td>0.250823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont5     cont6  \\\n",
       "0   1    B    B    B    C    B    B    A    E    C  ...  0.400361  0.160266   \n",
       "1   2    B    B    A    A    B    D    A    F    A  ...  0.533087  0.558922   \n",
       "2   3    A    A    A    C    B    D    A    D    A  ...  0.650609  0.375348   \n",
       "3   4    B    B    A    C    B    D    A    E    C  ...  0.668980  0.239061   \n",
       "4   6    A    A    A    C    B    D    A    E    A  ...  0.686964  0.420667   \n",
       "\n",
       "      cont7     cont8     cont9    cont10    cont11    cont12    cont13  kfold  \n",
       "0  0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850      0  \n",
       "1  0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083      2  \n",
       "2  0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846      4  \n",
       "3  0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682      3  \n",
       "4  0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823      1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate target from features\n",
    "y = df_train['target']\n",
    "features = df_train.drop(['target'], axis=1)\n",
    "\n",
    "# Preview features\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b294a8-c7de-4857-9696-2d8a62525f8c",
   "metadata": {},
   "source": [
    "## Tutorial stops before step 3 below ...\n",
    "Abishek is handling the ordinal encoding and stripping out target on each loop.  Feels like we could do this before the loop and simplify the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a79ba9af-45d8-469e-81ab-7568955f6df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 15s\n",
      "0 0.7157593224363182\n",
      "Wall time: 3min 19s\n",
      "1 0.7160153248020477\n",
      "Wall time: 3min 23s\n",
      "2 0.7179753915186063\n",
      "Wall time: 3min 24s\n",
      "3 0.7177027838963904\n",
      "Wall time: 3min 24s\n",
      "4 0.7159340302614421\n"
     ]
    }
   ],
   "source": [
    "final_predictions = []\n",
    "results = []\n",
    "\n",
    "for fold in range(5):\n",
    "    x_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n",
    "    x_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n",
    "    x_test = df_test.copy()\n",
    "\n",
    "    y_train = x_train.target\n",
    "    y_valid = x_valid.target\n",
    "\n",
    "    x_train = x_train[useful_features]\n",
    "    x_valid = x_valid[useful_features]\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    x_train[object_cols] = ordinal_encoder.fit_transform(x_train[object_cols])\n",
    "    x_valid[object_cols] = ordinal_encoder.transform(x_valid[object_cols])\n",
    "    x_test[object_cols] = ordinal_encoder.transform(x_test[object_cols])\n",
    "\n",
    "    xgb_params_tutorial = {\n",
    "        'random_state': fold,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "\n",
    "    xgb_params_from_gridsearch = {\n",
    "        'n_estimators': 5000,\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.2,\n",
    "        'max_depth': 3,\n",
    "        'booster': 'gbtree',\n",
    "        'reg_lambda': 0.2,\n",
    "        'reg_alpha': 15,\n",
    "        'random_state': fold,\n",
    "        'n_jobs': -1,\n",
    "        # 'gpu_id': 0,\n",
    "        # 'tree_method': 'gpu_hist',\n",
    "        # 'predictor': 'gpu_predictor'\n",
    "    }\n",
    "\n",
    "    # xgb_model = XGBRegressor(**xgb_params_tutorial)\n",
    "    xgb_model = XGBRegressor(**xgb_params_from_gridsearch)\n",
    "\n",
    "    %time xgb_model.fit(x_train, y_train)\n",
    "\n",
    "    preds_valid = xgb_model.predict(x_valid)\n",
    "    test_preds = xgb_model.predict(x_test)\n",
    "    final_predictions.append(test_preds)\n",
    "\n",
    "    mae = mean_squared_error(y_valid, preds_valid, squared=False)\n",
    "    results.append(mae)\n",
    "\n",
    "    print(fold, mae)\n",
    "\n",
    "print(f\"Average MAE: {sum(results)/len(results) :0.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d66c4-0151-4aff-a415-4d562c1d89e9",
   "metadata": {},
   "source": [
    "### Current best score\n",
    "    Local: 0.71668 (5-fold)\n",
    "    Kaggle-test: 0.71787 (V5 10-fold)\n",
    "    Kaggle-result: 0.71853 (V5 10-fold)\n",
    "\n",
    "Tutorial run as published results in:\n",
    "\n",
    "    0  0.7242812912900478\n",
    "    1  0.7232810321072864\n",
    "    2  0.725452249623988\n",
    "    3  0.725286377838993\n",
    "    4  0.7242629367174096\n",
    "    avg ~= 0.725\n",
    "    \n",
    "Upgrading to use settings from GridSearchCV work:\n",
    "\n",
    "    Local: 0.71668 (5-fold)\n",
    "    Kaggle-test: 0.71787 (V5 10-fold)\n",
    "    Kagle-result: 0.71853 (V5 10-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f013181b-4e70-4cfc-bd48-6ca1371b8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(np.column_stack(final_predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122bea10-60b6-4bd5-b8f4-71e4bc075a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission.target = preds\n",
    "# sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b473c0-94bb-4565-8aad-513359cbc4c3",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the data\n",
    "\n",
    "Next, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  \n",
    "\n",
    "In the **[Categorical Variables lesson](https://www.kaggle.com/alexisbcook/categorical-variables)** in the Intermediate Machine Learning course, you learned several different ways to encode categorical variables in a dataset.  In this notebook, we'll use ordinal encoding and save our encoded features as new variables `X` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca734432-0b22-47c4-8607-d8b6ebe3ffc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.389470</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.869850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668980</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.540150</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686964</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.648182</td>\n",
       "      <td>0.684501</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>1.000773</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.625849</td>\n",
       "      <td>0.250823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  ...     cont5  \\\n",
       "0   1   1.0   1.0   1.0   2.0   1.0   1.0   0.0   4.0   2.0  ...  0.400361   \n",
       "1   2   1.0   1.0   0.0   0.0   1.0   3.0   0.0   5.0   0.0  ...  0.533087   \n",
       "2   3   0.0   0.0   0.0   2.0   1.0   3.0   0.0   3.0   0.0  ...  0.650609   \n",
       "3   4   1.0   1.0   0.0   2.0   1.0   3.0   0.0   4.0   2.0  ...  0.668980   \n",
       "4   6   0.0   0.0   0.0   2.0   1.0   3.0   0.0   4.0   0.0  ...  0.686964   \n",
       "\n",
       "      cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
       "0  0.160266  0.310921  0.389470  0.267559  0.237281  0.377873  0.322401   \n",
       "1  0.558922  0.516294  0.594928  0.341439  0.906013  0.921701  0.261975   \n",
       "2  0.375348  0.902567  0.555205  0.843531  0.748809  0.620126  0.541474   \n",
       "3  0.239061  0.732948  0.679618  0.574844  0.346010  0.714610  0.540150   \n",
       "4  0.420667  0.648182  0.684501  0.956692  1.000773  0.776742  0.625849   \n",
       "\n",
       "     cont13  kfold  \n",
       "0  0.869850      0  \n",
       "1  0.465083      2  \n",
       "2  0.763846      4  \n",
       "3  0.280682      3  \n",
       "4  0.250823      1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of categorical columns\n",
    "object_cols = [col for col in features.columns if 'cat' in col]\n",
    "\n",
    "# ordinal-encode categorical columns\n",
    "X = features.copy()\n",
    "X_test = df_test.copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\n",
    "X_test[object_cols] = ordinal_encoder.transform(df_test[object_cols])\n",
    "\n",
    "# Preview the ordinal-encoded features\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c61e4f-574e-46ab-961c-665b4d84a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95690d1-d568-448a-be28-d623f99da5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_train_enc = lab_enc.fit_transform(y_train)\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_valid_enc = lab_enc.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297fba09-6802-4196-a153-cf770dceb849",
   "metadata": {},
   "source": [
    "# Step 4: Train a model\n",
    "\n",
    "Now that the data is prepared, the next step is to train a model.  \n",
    "\n",
    "If you took the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** courses, then you learned about **[Random Forests](https://www.kaggle.com/dansbecker/random-forests)**.  In the code cell below, we fit a random forest model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ceedf25-a982-456a-99ab-60f2490e8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rf = False\n",
    "\n",
    "if run_rf:\n",
    "    model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "    # Train the model (will take about 10 minutes to run)\n",
    "    %time model.fit(X_train, y_train)\n",
    "\n",
    "    pred_rf = model.predict(X_valid)\n",
    "    print(mean_squared_error(y_valid, pred_rf, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5b878f-0698-464d-b120-8f82b3d8d967",
   "metadata": {},
   "source": [
    "In the code cell above, we set `squared=False` to get the root mean squared error (RMSE) on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abbd9c-8e97-48fd-a204-55f52d5b0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215f2514-047b-4a0a-81cc-b8f119ddcc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_xgb = False\n",
    "\n",
    "if run_xgb:\n",
    "    # Feed the XGB into the model pipeline\n",
    "    my_pipeline = Pipeline(\n",
    "        [\n",
    "         # ('imputer', Imputer()),\n",
    "         ('xgbrg', XGBRegressor())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"xgbrg__n_estimators\": [5000, 10000],\n",
    "        \"xgbrg__learning_rate\": [0.05, 0.1],\n",
    "        \"xgbrg__subsample\": [0.8],\n",
    "        \"xgbrg__colsample_bytree\": [0.2],\n",
    "        \"xgbrg__max_depth\": [3, 5],\n",
    "        \"xgbrg__booster\": ['gbtree'],\n",
    "        \"xgbrg__reg_lambda\": [0.2, 0.4, 0.6],\n",
    "        \"xgbrg__reg_alpha\": [13, 15],\n",
    "        \"xgbrg__random_state\": [42],\n",
    "        \"xgbrg__n_jobs\": [-1],\n",
    "        # \"xgbrg__gpu_id\": [0],\n",
    "        # \"xgbrg__tree_method\": ['gpu_hist'],\n",
    "        # \"xgbrg__verbosity\": [1]\n",
    "    }\n",
    "\n",
    "    '''\n",
    "    params = {\n",
    "        'learning_rate': 0.07853392035787837,\n",
    "        'reg_lambda': 1.7549293092194938e-05,\n",
    "        'reg_alpha': 14.68267919457715,\n",
    "        'subsample': 0.8031450486786944,\n",
    "        'colsample_bytree': 0.170759104940733,\n",
    "        'max_depth': 3\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    searchCV = GridSearchCV(\n",
    "        my_pipeline,\n",
    "        cv=3,\n",
    "        param_grid=param_grid,\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    searchCV.fit(\n",
    "        X_train, y_train,\n",
    "        xgbrg__early_stopping_rounds=300,\n",
    "        xgbrg__eval_set=[(X_valid, y_valid)],\n",
    "        xgbrg__verbose=1000\n",
    "    )\n",
    "\n",
    "    print((time.time() - start)/60.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "543eede1-9808-47a7-8c1d-be0db5f22293",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'searchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ed6eb4f4f2ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Print the parameters which yield the best model performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(pd.DataFrame(grid.cv_results_))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'searchCV' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the parameters which yield the best model performance\n",
    "print(searchCV.best_estimator_)\n",
    "print(searchCV.best_score_)\n",
    "print(searchCV.best_params_)\n",
    "# print(pd.DataFrame(grid.cv_results_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "152acd94-17b7-41cc-b3dc-6c73a20fd320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.39030\n",
      "[1000]\tvalidation_0-rmse:0.72304\n",
      "[2000]\tvalidation_0-rmse:0.71998\n",
      "[3000]\tvalidation_0-rmse:0.71903\n",
      "[4000]\tvalidation_0-rmse:0.71885\n",
      "[4239]\tvalidation_0-rmse:0.71888\n",
      "2.8950045386950176\n",
      "0.7188357949796684\n"
     ]
    }
   ],
   "source": [
    "xgb_parameters = {\n",
    "    'n_estimators': 5000,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_jobs': -1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'booster': 'gbtree',\n",
    "    'reg_lambda': 0.2,\n",
    "    'reg_alpha': 15,\n",
    "    'random_state': 42,\n",
    "    # 'gpu_id': 0,\n",
    "    # 'tree_method': 'gpu_hist',\n",
    "    # 'predictor': 'gpu_predictor'\n",
    "}\n",
    "\n",
    "'''\n",
    "params = {\n",
    "    'learning_rate': 0.07853392035787837,\n",
    "    'reg_lambda': 1.7549293092194938e-05,\n",
    "    'reg_alpha': 14.68267919457715,\n",
    "    'subsample': 0.8031450486786944,\n",
    "    'colsample_bytree': 0.170759104940733,\n",
    "    'max_depth': 3\n",
    "}\n",
    "'''\n",
    "\n",
    "xgb_model = XGBRegressor(**xgb_parameters)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    early_stopping_rounds=300,\n",
    "    verbose=1000,\n",
    ")\n",
    "\n",
    "print((time.time()-start)/60.0)\n",
    "\n",
    "pred_xgb = xgb_model.predict(X_valid)\n",
    "\n",
    "print(mean_squared_error(y_valid, pred_xgb, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc98eb3-a1d5-47fc-9251-56d7006c4c78",
   "metadata": {},
   "source": [
    "### Using Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5386c3-a43e-4065-9a17-8a5ab4cc0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lgbm = False\n",
    "\n",
    "if run_lgbm:\n",
    "    from lightgbm import LGBMRegressor\n",
    "\n",
    "    lgbm_parameters = {\n",
    "        'metric': 'rmse',\n",
    "        'n_jobs': -1,\n",
    "        'n_estimators': 10000,\n",
    "        'reg_alpha': 10.924491968127692,\n",
    "        'reg_lambda': 17.396730654687218,\n",
    "        'colsample_bytree': 0.21497646795452627,\n",
    "        'subsample': 0.7582562557431147,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 12,\n",
    "        'num_leaves': 32,\n",
    "        'min_child_samples': 16,\n",
    "        'max_bin': 256,\n",
    "        'cat_l2': 0.025083670064082797\n",
    "    }\n",
    "\n",
    "    lgbm_model = LGBMRegressor(**lgbm_parameters)\n",
    "    lgbm_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=((X_valid, y_valid)),\n",
    "        verbose=-1,\n",
    "        early_stopping_rounds=64,\n",
    "        categorical_feature=object_cols\n",
    "    )\n",
    "\n",
    "    pred_lgbm = lgbm_model.predict(X_valid)\n",
    "\n",
    "    print(mean_squared_error(y_valid, pred_lgbm, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51519763-5cd3-4c05-8c55-8afb45aa7a03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TPOT to find best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e296581-66d7-472b-a3f1-4edab52015ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ae0dac-1693-4bc0-bafa-140f858d4070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b462c4601e479484319d28495e7116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/10 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\stopit\\utils.py\", line 145, in wrapper\n    result = func(*args, **kwargs)\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\gp_deap.py\", line 420, in _wrapped_cross_val_score\n    cv_iter = list(cv.split(features, target, groups))\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\sklearn\\model_selection\\_split.py\", line 336, in split\n    for train, test in super().split(X, y, groups):\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\sklearn\\model_selection\\_split.py\", line 80, in split\n    for test_index in self._iter_test_masks(X, y, groups):\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\sklearn\\model_selection\\_split.py\", line 697, in _iter_test_masks\n    test_folds = self._make_test_folds(X, y)\n  File \"C:\\Users\\chris\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\sklearn\\model_selection\\_split.py\", line 666, in _make_test_folds\n    raise ValueError(\"n_splits=%d cannot be greater than the\"\nValueError: n_splits=5 cannot be greater than the number of members in each class.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    815\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m                 self._pop, _ = eaMuPlusLambda(\n\u001b[0m\u001b[0;32m    817\u001b[0m                     \u001b[0mpopulation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[1;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function, log_file)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_evaluate_individuals\u001b[1;34m(self, population, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m   1566\u001b[0m                         )\n\u001b[1;32m-> 1567\u001b[1;33m                         tmp_result_scores = parallel(\n\u001b[0m\u001b[0;32m   1568\u001b[0m                             delayed(partial_wrapped_cross_val_score)(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    861\u001b[0m                     \u001b[1;31m# raise the exception if it's our last attempt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    852\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                     \u001b[1;31m# Delete the temporary cache before exiting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m             \u001b[1;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m             \u001b[1;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    962\u001b[0m                 \u001b[1;34m\"A pipeline has not yet been optimized. Please call fit() first.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m             )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-47f8d45c90a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Export the optimized pipeline as Python code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tpot_products_pipeline.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\FourthBrain\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self, output_file_name, data_file_path)\u001b[0m\n\u001b[0;32m   1278\u001b[0m         \"\"\"\n\u001b[0;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimized_pipeline\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m   1281\u001b[0m                 \u001b[1;34m\"A pipeline has not yet been optimized. Please call fit() first.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m             )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "# TPOT for classification\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Instantiate and train a TPOT auto-ML classifier\n",
    "tpot = TPOTClassifier(\n",
    "    generations=1,\n",
    "    population_size=5,\n",
    "    subsample=0.05,\n",
    "    # config_dict='TPOT cuML',\n",
    "    verbosity=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "%time tpot.fit(X_train, y_train_enc)\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Export the optimized pipeline as Python code.\n",
    "tpot.export('tpot_products_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b982e-cf83-4be6-8daf-b9ad5a144062",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 5: Submit to the competition\n",
    "\n",
    "We'll begin by using the trained model to generate predictions, which we'll save to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49cd437-e84d-4de1-b71c-e853c970802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to generate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'target': predictions})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bee64d-7b41-472d-9196-7ff4fc3240c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.07853392035787837,\n",
    "    'reg_lambda': 1.7549293092194938e-05,\n",
    "    'reg_alpha': 14.68267919457715,\n",
    "    'subsample': 0.8031450486786944,\n",
    "    'colsample_bytree': 0.170759104940733,\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "model = XGBRegressor(\n",
    "    random_state=0, \n",
    "    #tree_method='gpu_hist',\n",
    "    #gpu_id=0,\n",
    "    #predictor=\"gpu_predictor\",\n",
    "    n_estimators=5000,\n",
    "    **params\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    xtrain, ytrain,\n",
    "    early_stopping_rounds=300,\n",
    "    eval_set=[(xvalid, yvalid)],\n",
    "    verbose=1000\n",
    ")\n",
    "\n",
    "preds_valid = model.predict(xvalid)\n",
    "test_preds = model.predict(xtest)\n",
    "final_predictions.append(test_preds)\n",
    "rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "print(fold, rmse)\n",
    "scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
